{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3dApWFq1wiy",
        "outputId": "2169f623-cc0b-4fe6-9f8b-b3edcc60f778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "4RTSKmBcsj1q",
        "outputId": "682af234-af1b-4000-fc2e-1e28602c5ca1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "class EVEnergyPredictor:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.model = None\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.feature_columns = None\n",
        "        self.categorical_mappings = {\n",
        "            'Terrain_Type': ['hilly', 'non-hilly'],\n",
        "            'Traffic': ['no traffic', 'present traffic']\n",
        "        }\n",
        "\n",
        "    def cap_outliers(self, df, column, whisker_factor=1.5):\n",
        "        \"\"\"Cap outliers using IQR method.\"\"\"\n",
        "        q1 = df[column].quantile(0.25)\n",
        "        q3 = df[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - whisker_factor * iqr\n",
        "        upper_bound = q3 + whisker_factor * iqr\n",
        "        df[column] = df[column].clip(lower_bound, upper_bound)\n",
        "        return df\n",
        "\n",
        "    def load_and_preprocess(self):\n",
        "        \"\"\"Load and preprocess the historical data with outlier capping\"\"\"\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        df = df[['EVS Bus', 'Temperature', 'Distance', 'Passenger Count',\n",
        "                'speed(km/hr)', 'Energy Consumption',\n",
        "                'Terrain Description', 'Traffic Description']]\n",
        "        df.columns = ['Bus_ID', 'Temperature', 'Distance_km', 'Passengers',\n",
        "                     'Average_Speed', 'Energy_kWh', 'Terrain_Type', 'Traffic']\n",
        "\n",
        "        df = df[~df['Traffic'].str.contains('light traffic', case=False, na=False)]\n",
        "\n",
        "        df = df.dropna()\n",
        "        df = df[df['Energy_kWh'] > 0]\n",
        "\n",
        "        df['Terrain_Type'] = df['Terrain_Type'].str.strip().str.lower()\n",
        "        df['Traffic'] = df['Traffic'].str.strip().str.lower()\n",
        "\n",
        "        df = df[df['Traffic'].isin(['no traffic', 'present traffic'])]\n",
        "\n",
        "        # Binary encoding categorical features\n",
        "        df['Terrain_Type'] = df['Terrain_Type'].map({'hilly': 1, 'non-hilly': 0})\n",
        "        df['Traffic'] = df['Traffic'].map({'present traffic': 1, 'no traffic': 0})\n",
        "\n",
        "        #feature interactions and nonlinear transformations\n",
        "        df['Distance_Squared'] = df['Distance_km'] ** 2\n",
        "        df['Speed_Squared'] = df['Average_Speed'] ** 2\n",
        "        df['Distance_Speed'] = df['Distance_km'] * df['Average_Speed']\n",
        "        df['Distance_Terrain'] = df['Distance_km'] * df['Terrain_Type']\n",
        "        df['Speed_Terrain'] = df['Average_Speed'] * df['Terrain_Type']\n",
        "        df['Passengers_Distance'] = df['Passengers'] * df['Distance_km']\n",
        "\n",
        "        # Outlier capping\n",
        "        base_numeric_cols = [\"Distance_km\", \"Passengers\", \"Temperature\", \"Average_Speed\", \"Energy_kWh\"]\n",
        "        derived_numeric_cols = [\"Distance_Squared\", \"Speed_Squared\", \"Distance_Speed\",\n",
        "                                \"Distance_Terrain\", \"Speed_Terrain\", \"Passengers_Distance\"]\n",
        "\n",
        "        for col in base_numeric_cols:\n",
        "            df = self.cap_outliers(df, col)\n",
        "\n",
        "        # Store the processed data\n",
        "        self.historical_data = df\n",
        "        return df\n",
        "\n",
        "    def train_model(self, test_size=0.2, random_state=42, model_type='gradient_boosting'):\n",
        "        \"\"\"Train non-linear regression model with train-test split and evaluation\"\"\"\n",
        "        if not hasattr(self, 'historical_data'):\n",
        "            self.load_and_preprocess()\n",
        "\n",
        "        df = self.historical_data.copy()\n",
        "\n",
        "        # Prepare features and target\n",
        "        self.base_numeric_features = [\"Distance_km\", \"Passengers\", \"Temperature\", \"Average_Speed\"]\n",
        "        self.derived_numeric_features = [\"Distance_Squared\", \"Speed_Squared\", \"Distance_Speed\",\n",
        "                                         \"Distance_Terrain\", \"Speed_Terrain\", \"Passengers_Distance\"]\n",
        "        self.numeric_features = self.base_numeric_features + self.derived_numeric_features\n",
        "        self.categorical_cols = [\"Terrain_Type\", \"Traffic\"]\n",
        "        self.feature_columns = self.numeric_features + self.categorical_cols\n",
        "\n",
        "        X = df[self.feature_columns]\n",
        "        y = df[\"Energy_kWh\"]\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Normalize only numeric features\n",
        "        if len(self.numeric_features) > 0:\n",
        "            X_train[self.numeric_features] = self.scaler.fit_transform(X_train[self.numeric_features])\n",
        "            X_test[self.numeric_features] = self.scaler.transform(X_test[self.numeric_features])\n",
        "\n",
        "        # Initialize model based on type\n",
        "        if model_type == 'gradient_boosting':\n",
        "            self.model = GradientBoostingRegressor(\n",
        "                n_estimators=100,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=4,\n",
        "                min_samples_split=5,\n",
        "                random_state=random_state\n",
        "            )\n",
        "        elif model_type == 'svr':\n",
        "            self.model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "        elif model_type == 'kernel_ridge':\n",
        "            self.model = KernelRidge(alpha=1.0, kernel='rbf', gamma=0.1)\n",
        "        elif model_type == 'random_forest':\n",
        "            self.model = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                min_samples_split=5,\n",
        "                random_state=random_state\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
        "\n",
        "        # Training model and making predictions\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        train_pred = self.model.predict(X_train)\n",
        "        test_pred = self.model.predict(X_test)\n",
        "\n",
        "        # Store predictions\n",
        "        self.train_results = pd.DataFrame({\n",
        "            'Actual': y_train,\n",
        "            'Predicted': train_pred\n",
        "        })\n",
        "        self.test_results = pd.DataFrame({\n",
        "            'Actual': y_test,\n",
        "            'Predicted': test_pred\n",
        "        })\n",
        "\n",
        "        # Evaluate model\n",
        "        self.evaluate_model(y_train, train_pred, y_test, test_pred)\n",
        "\n",
        "        # Store feature medians for prediction\n",
        "        self.feature_medians = X.median()\n",
        "\n",
        "        # Feature importance for tree-based models\n",
        "        if model_type in ['gradient_boosting', 'random_forest']:\n",
        "            self.plot_feature_importance()\n",
        "#calculating metrics for train and test set\n",
        "    def evaluate_model(self, y_train, train_pred, y_test, test_pred):\n",
        "        \"\"\"Calculate and print evaluation metrics\"\"\"\n",
        "\n",
        "        train_mae = mean_absolute_error(y_train, train_pred)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "        train_r2 = r2_score(y_train, train_pred)\n",
        "        train_mape = np.mean(np.abs((y_train - train_pred) / y_train)) * 100\n",
        "\n",
        "        test_mae = mean_absolute_error(y_test, test_pred)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "        test_r2 = r2_score(y_test, test_pred)\n",
        "        test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
        "\n",
        "        train_accuracy = max(0, 100 - train_mape)\n",
        "        test_accuracy = max(0, 100 - test_mape)\n",
        "\n",
        "        print(\"\\nModel Evaluation Metrics:\")\n",
        "        print(f\"{'Metric':<15}{'Training':<15} {'Test':<15}\")\n",
        "        print(f\"{'MAE':<15}{train_mae:.4f} {test_mae:.4f}\")\n",
        "        print(f\"{'RMSE':<15}{train_rmse:.4f} {test_rmse:.4f}\")\n",
        "        print(f\"{'R²':<15}{train_r2:.4f} {test_r2:.4f}\")\n",
        "        print(f\"{'MAPE (%)':<15}{train_mape:.2f} {test_mape:.2f}\")\n",
        "        print(f\"{'Accuracy (%)':<15}{train_accuracy:.2f} {test_accuracy:.2f}\")\n",
        "\n",
        "        self.metrics = {\n",
        "            'train_mae': train_mae,\n",
        "            'train_rmse': train_rmse,\n",
        "            'train_r2': train_r2,\n",
        "            'train_mape': train_mape,\n",
        "            'train_accuracy': train_accuracy,\n",
        "            'test_mae': test_mae,\n",
        "            'test_rmse': test_rmse,\n",
        "            'test_r2': test_r2,\n",
        "            'test_mape': test_mape,\n",
        "            'test_accuracy': test_accuracy\n",
        "        }\n",
        "\n",
        "    def plot_actual_vs_predicted(self, num_trips=500, dataset='test'):\n",
        "        \"\"\"Plot actual vs predicted energy consumption\"\"\"\n",
        "        if not hasattr(self, 'train_results'):\n",
        "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "        if dataset == 'train':\n",
        "            plot_data = self.train_results.head(num_trips).copy()\n",
        "            title = 'Training Set'\n",
        "        else:\n",
        "            plot_data = self.test_results.head(num_trips).copy()\n",
        "            title = 'Test Set'\n",
        "\n",
        "        plot_data['Trip_Index'] = range(1, len(plot_data)+1)\n",
        "\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.plot(plot_data['Trip_Index'], plot_data['Actual'],\n",
        "                label='Actual Energy Consumption', color='blue', alpha=0.7)\n",
        "        plt.plot(plot_data['Trip_Index'], plot_data['Predicted'],\n",
        "                label='Predicted Energy Consumption', color='red', alpha=0.7, linestyle='--')\n",
        "\n",
        "        plt.title(f'Actual vs Predicted Energy Consumption ({title})')\n",
        "        plt.xlabel('Trip Index')\n",
        "        plt.ylabel('Energy Consumption (kWh)')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.scatter(plot_data['Actual'], plot_data['Predicted'], alpha=0.5)\n",
        "\n",
        "        max_val = max(plot_data['Actual'].max(), plot_data['Predicted'].max())\n",
        "        min_val = min(plot_data['Actual'].min(), plot_data['Predicted'].min())\n",
        "        plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
        "\n",
        "        plt.title(f'Actual vs Predicted Scatter Plot ({title})')\n",
        "        plt.xlabel('Actual Energy Consumption (kWh)')\n",
        "        plt.ylabel('Predicted Energy Consumption (kWh)')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.axis('equal')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_feature_importance(self):\n",
        "        \"\"\"Plot feature importance for tree-based models\"\"\"\n",
        "        if not hasattr(self, 'model') or not hasattr(self.model, 'feature_importances_'):\n",
        "            return\n",
        "\n",
        "        importances = self.model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.title('Feature Importance')\n",
        "        plt.bar(range(len(importances)), importances[indices], align='center')\n",
        "        plt.xticks(range(len(importances)), [self.feature_columns[i] for i in indices], rotation=90)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_residuals(self, dataset='test'):\n",
        "        \"\"\"Plot residuals analysis\"\"\"\n",
        "        if not hasattr(self, 'train_results'):\n",
        "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "        if dataset == 'train':\n",
        "            results = self.train_results\n",
        "            title = 'Training Set'\n",
        "        else:\n",
        "            results = self.test_results\n",
        "            title = 'Test Set'\n",
        "\n",
        "        residuals = results['Actual'] - results['Predicted']\n",
        "\n",
        "        # Residuals vs Predicted\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.scatter(results['Predicted'], residuals, alpha=0.5)\n",
        "        plt.axhline(y=0, color='r', linestyle='--')\n",
        "        plt.xlabel('Predicted Values')\n",
        "        plt.ylabel('Residuals')\n",
        "        plt.title(f'Residuals vs Predicted ({title})')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Residuals distribution\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.hist(residuals, bins=30, alpha=0.7)\n",
        "        plt.xlabel('Residual Value')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.title(f'Residuals Distribution ({title})')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def find_best_model(self, test_size=0.2, random_state=42):\n",
        "        \"\"\"Find the best non-linear model through cross-validation\"\"\"\n",
        "        if not hasattr(self, 'historical_data'):\n",
        "            self.load_and_preprocess()\n",
        "\n",
        "        df = self.historical_data.copy()\n",
        "\n",
        "        # Prepare features and target\n",
        "        self.base_numeric_features = [\"Distance_km\", \"Passengers\", \"Temperature\", \"Average_Speed\"]\n",
        "        self.derived_numeric_features = [\"Distance_Squared\", \"Speed_Squared\", \"Distance_Speed\",\n",
        "                                         \"Distance_Terrain\", \"Speed_Terrain\", \"Passengers_Distance\"]\n",
        "        self.numeric_features = self.base_numeric_features + self.derived_numeric_features\n",
        "        self.categorical_cols = [\"Terrain_Type\", \"Traffic\"]\n",
        "        self.feature_columns = self.numeric_features + self.categorical_cols\n",
        "\n",
        "        X = df[self.feature_columns]\n",
        "        y = df[\"Energy_kWh\"]\n",
        "\n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Normalize only numeric features\n",
        "        if len(self.numeric_features) > 0:\n",
        "            X_train[self.numeric_features] = self.scaler.fit_transform(X_train[self.numeric_features])\n",
        "            X_test[self.numeric_features] = self.scaler.transform(X_test[self.numeric_features])\n",
        "\n",
        "        # Define models to try\n",
        "        models = {\n",
        "            'Gradient Boosting': GradientBoostingRegressor(random_state=random_state),\n",
        "            'Random Forest': RandomForestRegressor(random_state=random_state),\n",
        "            'SVR': SVR(),\n",
        "        }\n",
        "\n",
        "        # Results storage\n",
        "        results = {}\n",
        "\n",
        "        # Train and evaluate each model\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions\n",
        "            train_pred = model.predict(X_train)\n",
        "            test_pred = model.predict(X_test)\n",
        "\n",
        "            # Metrics\n",
        "            train_r2 = r2_score(y_train, train_pred)\n",
        "            test_r2 = r2_score(y_test, test_pred)\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "            test_mape = np.mean(np.abs((y_test - test_pred) / y_test)) * 100\n",
        "            test_accuracy = max(0, 100 - test_mape)\n",
        "\n",
        "            print(f\"{name} - Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'train_r2': train_r2,\n",
        "                'test_r2': test_r2,\n",
        "                'test_rmse': test_rmse,\n",
        "                'test_accuracy': test_accuracy\n",
        "            }\n",
        "\n",
        "        # Find best model based on test R²\n",
        "        best_model_name = max(results, key=lambda k: results[k]['test_r2'])\n",
        "        best_model = results[best_model_name]['model']\n",
        "\n",
        "        print(f\"\\nBest model: {best_model_name} with Test R²: {results[best_model_name]['test_r2']:.4f}\")\n",
        "\n",
        "        # Set the best model as the current model\n",
        "        self.model = best_model\n",
        "\n",
        "        # Make predictions with best model\n",
        "        train_pred = best_model.predict(X_train)\n",
        "        test_pred = best_model.predict(X_test)\n",
        "\n",
        "        # Store predictions\n",
        "        self.train_results = pd.DataFrame({\n",
        "            'Actual': y_train,\n",
        "            'Predicted': train_pred\n",
        "        })\n",
        "        self.test_results = pd.DataFrame({\n",
        "            'Actual': y_test,\n",
        "            'Predicted': test_pred\n",
        "        })\n",
        "\n",
        "        # Evaluate best model\n",
        "        self.evaluate_model(y_train, train_pred, y_test, test_pred)\n",
        "\n",
        "        # Store feature medians for prediction\n",
        "        self.feature_medians = X.median()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        \"\"\"Predict energy consumption with non-linear features\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "        # Create template with all expected base feature columns\n",
        "        base_features = {}\n",
        "        for num_feat in self.base_numeric_features:\n",
        "            if num_feat in input_data:\n",
        "                base_features[num_feat] = input_data[num_feat]\n",
        "            else:\n",
        "                # Use historical median if not provided\n",
        "                base_features[num_feat] = self.feature_medians[num_feat]\n",
        "\n",
        "        # Add categorical features\n",
        "        if 'Terrain_Type' in input_data:\n",
        "            base_features['Terrain_Type'] = 1 if str(input_data['Terrain_Type']).lower() in ['hilly', '1'] else 0\n",
        "        else:\n",
        "            base_features['Terrain_Type'] = 0\n",
        "\n",
        "        if 'Traffic' in input_data:\n",
        "            base_features['Traffic'] = 1 if str(input_data['Traffic']).lower() in ['present traffic', '1'] else 0\n",
        "        else:\n",
        "            base_features['Traffic'] = 0\n",
        "\n",
        "        # Create derived features\n",
        "        derived_features = {\n",
        "            'Distance_Squared': base_features['Distance_km'] ** 2,\n",
        "            'Speed_Squared': base_features['Average_Speed'] ** 2,\n",
        "            'Distance_Speed': base_features['Distance_km'] * base_features['Average_Speed'],\n",
        "            'Distance_Terrain': base_features['Distance_km'] * base_features['Terrain_Type'],\n",
        "            'Speed_Terrain': base_features['Average_Speed'] * base_features['Terrain_Type'],\n",
        "            'Passengers_Distance': base_features['Passengers'] * base_features['Distance_km']\n",
        "        }\n",
        "\n",
        "        # Combine all features\n",
        "        all_features = {**base_features, **derived_features}\n",
        "\n",
        "        # Create DataFrame with features in the correct order\n",
        "        template = pd.DataFrame(columns=self.feature_columns)\n",
        "        for feature in self.feature_columns:\n",
        "            template[feature] = [all_features[feature]]\n",
        "\n",
        "        # Normalize only numeric features\n",
        "        if len(self.numeric_features) > 0:\n",
        "            template[self.numeric_features] = self.scaler.transform(template[self.numeric_features])\n",
        "\n",
        "        # Predict and ensure reasonable values\n",
        "        prediction = max(self.model.predict(template)[0], 0.1)\n",
        "        return min(prediction, 100)  # Cap predictions at 100 kWh\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"Save the trained model and components\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "        joblib.dump({\n",
        "            'model': self.model,\n",
        "            'scaler': self.scaler,\n",
        "            'feature_columns': self.feature_columns,\n",
        "            'numeric_features': self.numeric_features,\n",
        "            'categorical_cols': self.categorical_cols,\n",
        "            'feature_medians': self.feature_medians,\n",
        "            'historical_data': self.historical_data,\n",
        "            'train_results': self.train_results,\n",
        "            'test_results': self.test_results,\n",
        "            'base_numeric_features': self.base_numeric_features,\n",
        "            'derived_numeric_features': self.derived_numeric_features,\n",
        "            'metrics': getattr(self, 'metrics', None)\n",
        "        }, path)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, path):\n",
        "        \"\"\"Load a saved model\"\"\"\n",
        "        components = joblib.load(path)\n",
        "        predictor = cls(None)\n",
        "        predictor.model = components['model']\n",
        "        predictor.scaler = components['scaler']\n",
        "        predictor.feature_columns = components['feature_columns']\n",
        "        predictor.numeric_features = components['numeric_features']\n",
        "        predictor.categorical_cols = components['categorical_cols']\n",
        "        predictor.feature_medians = components['feature_medians']\n",
        "        predictor.historical_data = components.get('historical_data', None)\n",
        "        predictor.train_results = components.get('train_results', None)\n",
        "        predictor.test_results = components.get('test_results', None)\n",
        "        predictor.base_numeric_features = components.get('base_numeric_features', None)\n",
        "        predictor.derived_numeric_features = components.get('derived_numeric_features', None)\n",
        "        predictor.metrics = components.get('metrics', None)\n",
        "        return predictor\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Initializing predictor with non-linear regression capability...\")\n",
        "    predictor = EVEnergyPredictor('/content/drive/MyDrive/extracted_evs_data (1).csv')\n",
        "    predictor.load_and_preprocess()\n",
        "    print(f\"Loaded {len(predictor.historical_data)} samples after preprocessing\")\n",
        "\n",
        "    # Find the best model\n",
        "    print(\"\\nFinding the best model...\")\n",
        "    predictor.find_best_model(test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Get the first 100 rows for the test set\n",
        "if hasattr(predictor, 'test_results'):\n",
        "    test_plot_data = predictor.test_results.head(100).copy()\n",
        "    print(\"\\nTest Set Actual vs Predicted (First 100 trips):\")\n",
        "    print(test_plot_data.to_string())\n",
        "\n",
        "    test_plot_data.to_csv('test_actual_vs_predicted_100.csv', index=False)\n",
        "    print(\"\\nSaved 'test_actual_vs_predicted_100.csv'\")\n",
        "\n",
        "    predictor.plot_actual_vs_predicted(num_trips=100, dataset='test')\n",
        "    predictor.plot_residuals(dataset='test')\n",
        "\n",
        "    if hasattr(predictor.model, 'feature_importances_'):\n",
        "        predictor.plot_feature_importance()\n",
        "\n",
        "    predictor.save_model('/content/drive/MyDrive/ev_energy_predictor_nonlinear.joblib')\n",
        "    print(\"Model trained and saved\")\n",
        "\n",
        "   #new predictions\n",
        "def predict_multiple_trips(self, num_trips=14, use_historical_data=True):\n",
        "    \"\"\"\n",
        "    Predict energy consumption for a specific number of trips.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    num_trips : int\n",
        "        Number of trips to predict for\n",
        "    use_historical_data : bool\n",
        "        If True, use samples from historical data for predictions\n",
        "        If False, use the median values from historical data for all trips\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with trip information and predictions\n",
        "    \"\"\"\n",
        "    if self.model is None:\n",
        "        raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "    if not hasattr(self, 'historical_data'):\n",
        "        raise ValueError(\"Historical data not available. Load data first.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    if use_historical_data:\n",
        "        # Sample from historical data with replacement\n",
        "        sampled_indices = np.random.choice(\n",
        "            len(self.historical_data),\n",
        "            size=num_trips,\n",
        "            replace=True if num_trips > len(self.historical_data) else False\n",
        "        )\n",
        "\n",
        "        for i, idx in enumerate(sampled_indices):\n",
        "            trip_data = self.historical_data.iloc[idx]\n",
        "\n",
        "            input_data = {\n",
        "                'Distance_km': trip_data['Distance_km'],\n",
        "                'Passengers': trip_data['Passengers'],\n",
        "                'Temperature': trip_data['Temperature'],\n",
        "                'Average_Speed': trip_data['Average_Speed'],\n",
        "                'Terrain_Type': 'hilly' if trip_data['Terrain_Type'] == 1 else 'non-hilly',\n",
        "                'Traffic': 'present traffic' if trip_data['Traffic'] == 1 else 'no traffic'\n",
        "            }\n",
        "\n",
        "            prediction = self.predict(input_data)\n",
        "\n",
        "            result = {\n",
        "                'Trip_ID': i + 1,\n",
        "                **input_data,\n",
        "                'Predicted_Energy_kWh': prediction\n",
        "            }\n",
        "            results.append(result)\n",
        "    else:\n",
        "\n",
        "        for i in range(num_trips):\n",
        "            input_data = {\n",
        "                'Distance_km': self.feature_medians['Distance_km'],\n",
        "                'Passengers': self.feature_medians['Passengers'],\n",
        "                'Temperature': self.feature_medians['Temperature'],\n",
        "                'Average_Speed': self.feature_medians['Average_Speed'],\n",
        "                'Terrain_Type': 'hilly' if self.feature_medians['Terrain_Type'] > 0.5 else 'non-hilly',\n",
        "                'Traffic': 'present traffic' if self.feature_medians['Traffic'] > 0.5 else 'no traffic'\n",
        "            }\n",
        "\n",
        "\n",
        "            prediction = self.predict(input_data)\n",
        "\n",
        "            result = {\n",
        "                'Trip_ID': i + 1,\n",
        "                **input_data,\n",
        "                'Predicted_Energy_kWh': prediction\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def display_predictions(self, predictions_df):\n",
        "    \"\"\"\n",
        "    Display predictions in a clear, tabular format and create a simple visualization\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    predictions_df : pandas.DataFrame\n",
        "        DataFrame with predictions from predict_multiple_trips()\n",
        "    \"\"\"\n",
        "    # Print tabular results\n",
        "    print(\"\\nPREDICTED ENERGY CONSUMPTION FOR TRIPS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    formatted_df = predictions_df.copy()\n",
        "\n",
        "    # Format numeric columns\n",
        "    formatted_df['Distance_km'] = formatted_df['Distance_km'].round(1)\n",
        "    formatted_df['Temperature'] = formatted_df['Temperature'].round(1)\n",
        "    formatted_df['Average_Speed'] = formatted_df['Average_Speed'].round(1)\n",
        "    formatted_df['Predicted_Energy_kWh'] = formatted_df['Predicted_Energy_kWh'].round(2)\n",
        "\n",
        "    # Print the table\n",
        "    print(formatted_df.to_string(index=False))\n",
        "\n",
        "    # Calculate summary statistics\n",
        "    total_energy = formatted_df['Predicted_Energy_kWh'].sum()\n",
        "    avg_energy = formatted_df['Predicted_Energy_kWh'].mean()\n",
        "    min_energy = formatted_df['Predicted_Energy_kWh'].min()\n",
        "    max_energy = formatted_df['Predicted_Energy_kWh'].max()\n",
        "\n",
        "    print(\"\\nSUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Total predicted energy consumption: {total_energy:.2f} kWh\")\n",
        "    print(f\"Average energy per trip: {avg_energy:.2f} kWh\")\n",
        "    print(f\"Range: {min_energy:.2f} - {max_energy:.2f} kWh\")\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(formatted_df['Trip_ID'], formatted_df['Predicted_Energy_kWh'],\n",
        "            color='blue', alpha=0.7)\n",
        "    plt.axhline(y=avg_energy, color='r', linestyle='--',\n",
        "                label=f'Average: {avg_energy:.2f} kWh')\n",
        "    plt.title('Predicted Energy Consumption by Trip')\n",
        "    plt.xlabel('Trip ID')\n",
        "    plt.ylabel('Energy Consumption (kWh)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return total_energy, avg_energy\n",
        "\n",
        "# Add methods to EVEnergyPredictor class\n",
        "EVEnergyPredictor.predict_multiple_trips = predict_multiple_trips\n",
        "EVEnergyPredictor.display_predictions = display_predictions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predictor = EVEnergyPredictor.load_model('/content/drive/MyDrive/ev_energy_predictor_nonlinear.joblib')\n",
        "\n",
        "    trip_predictions = predictor.predict_multiple_trips(num_trips=14)\n",
        "\n",
        "    total, average = predictor.display_predictions(trip_predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
